import dash
from dash import dcc, html, Input, Output, dash_table
import pandas as pd
import numpy as np
import plotly.graph_objects as go

# ====== Artificial Data Generator ======

def generate_artificial_data(N=5, T=100, seed=42):
    np.random.seed(seed)
    data = []
    for asset_id in range(N):
        price = 100
        for day in range(T):
            open_price = price
            daily_return = np.random.normal(0, 0.01)
            high_return = np.random.uniform(0, 0.02)
            low_return = -np.random.uniform(0, 0.02)
            high_price = open_price * (1 + high_return)
            low_price = open_price * (1 + low_return)
            close_price = open_price * (1 + daily_return)
            price = close_price
            data.append({
                'asset': f"Asset_{asset_id}",
                'day': day,
                'open': open_price,
                'high': high_price,
                'low': low_price,
                'close': close_price
            })
    return pd.DataFrame(data)

# ====== Signal Detection Functions ======

def detect_intraday_reversals(df, intraday_range_threshold=0.015, close_open_tol=0.002, min_range_magnitude=0.01):
    df = df.copy()
    df['intraday_range'] = (df['high'] - df['low']) / df['open']
    df['net_return'] = (df['close'] - df['open']) / df['open']
    df['hl_move_pct'] = (df['high'] - df['low']) / df['open']
    df['intraday_reversal_signal'] = (
        (df['intraday_range'] > intraday_range_threshold) &
        (df['net_return'].abs() < close_open_tol) &
        (df['hl_move_pct'] > min_range_magnitude)
    ).astype(int)
    return df

def detect_streak_reversals(df, min_streak_len=3, min_avg_move=0.002):
    df = df.copy()
    df['daily_return'] = df['close'].pct_change()
    df['streak_reversal_signal'] = 0
    for asset, group in df.groupby('asset'):
        returns = group['daily_return'].values
        count = 1
        for i in range(1, len(returns)):
            if np.sign(returns[i]) == np.sign(returns[i-1]) and returns[i] != 0:
                count += 1
            else:
                if count >= min_streak_len:
                    avg_move = np.mean(returns[i-count:i])
                    if abs(avg_move) > min_avg_move:
                        idx = group.index[i]
                        df.loc[idx, 'streak_reversal_signal'] = 1
                count = 1
    return df

def mean_reversion_after_extreme(df, threshold=0.02):
    df = df.copy()
    df['daily_return'] = df['close'].pct_change()
    df['extreme_reversion_signal'] = 0
    for asset, group in df.groupby('asset'):
        idx = group.index
        ret = group['daily_return']
        for i in range(1, len(ret) - 1):
            if abs(ret.iloc[i]) > threshold and np.sign(ret.iloc[i]) != np.sign(ret.iloc[i + 1]):
                df.loc[idx[i + 1], 'extreme_reversion_signal'] = 1
    return df

def close_near_high_or_low(df, close_pct_thresh=0.02):
    df = df.copy()
    df['close_to_high'] = (df['high'] - df['close']) / df['high']
    df['close_to_low'] = (df['close'] - df['low']) / df['low']
    df['close_near_extreme_signal'] = (
        (df['close_to_high'] < close_pct_thresh) |
        (df['close_to_low'] < close_pct_thresh)
    ).astype(int)
    return df

def inside_day(df):
    df = df.copy()
    df['inside_day_signal'] = 0
    for asset, group in df.groupby('asset'):
        high_prev = group['high'].shift(1)
        low_prev = group['low'].shift(1)
        inside = (group['high'] <= high_prev) & (group['low'] >= low_prev)
        df.loc[group.index, 'inside_day_signal'] = inside.astype(int)
    return df

def outside_day(df):
    df = df.copy()
    df['outside_day_signal'] = 0
    for asset, group in df.groupby('asset'):
        high_prev = group['high'].shift(1)
        low_prev = group['low'].shift(1)
        outside = (group['high'] >= high_prev) & (group['low'] <= low_prev)
        df.loc[group.index, 'outside_day_signal'] = outside.astype(int)
    return df

def gap_open_and_reverse(df, gap_threshold=0.01):
    df = df.copy()
    df['gap'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)
    df['gap_reversal_signal'] = 0
    for asset, group in df.groupby('asset'):
        cond = (group['gap'].abs() > gap_threshold) & (
            np.sign(group['gap']) != np.sign((group['close'] - group['open']) / group['open']))
        df.loc[group.index, 'gap_reversal_signal'] = cond.astype(int)
    return df

def vol_clustering(df, window=5):
    df = df.copy()
    df['daily_return'] = df['close'].pct_change()
    df['volatility'] = df['daily_return'].rolling(window).std()
    df['vol_cluster_signal'] = (df['volatility'] > df['volatility'].rolling(window).mean()).astype(int)
    return df

def trend_following_after_breakout(df, window=20):
    df = df.copy()
    df['rolling_max'] = df['high'].rolling(window).max()
    df['breakout_signal'] = (df['close'] > df['rolling_max'].shift(1)).astype(int)
    return df

def price_vs_moving_average(df, ma_window=10):
    df = df.copy()
    df['ma'] = df['close'].rolling(ma_window).mean()
    df['above_ma_signal'] = (df['close'] > df['ma']).astype(int)
    return df

def volume_spike(df, volume_col='volume', threshold=2):
    df = df.copy()
    # generate synthetic volume if missing
    if volume_col not in df.columns:
        np.random.seed(42)
        df[volume_col] = np.random.normal(1_000_000, 200_000, len(df))
    df['vol_mean'] = df[volume_col].rolling(5).mean()
    df['volume_spike_signal'] = (df[volume_col] > threshold * df['vol_mean']).astype(int)
    return df

def high_low_volatility_spread(df, window=10):
    df = df.copy()
    df['hl_range'] = (df['high'] - df['low']) / df['close']
    df['vol_spread_signal'] = (df['hl_range'] > df['hl_range'].rolling(window).mean()).astype(int)
    return df

def relative_strength_index(df, period=14):
    df = df.copy()
    delta = df['close'].diff()
    gain = delta.clip(lower=0)
    loss = (-delta).clip(lower=0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / (avg_loss + 1e-9)
    rsi = 100 - (100 / (1 + rs))
    df['rsi'] = rsi
    df['rsi_signal'] = ((rsi < 30) | (rsi > 70)).astype(int)
    return df

# List of signal functions and their friendly names
SIGNAL_FUNCTIONS = [
    (detect_intraday_reversals, 'Intraday Reversals'),
    (detect_streak_reversals, 'Streak Reversals'),
    (mean_reversion_after_extreme, 'Mean Reversion After Extreme'),
    (close_near_high_or_low, 'Close Near High or Low'),
    (inside_day, 'Inside Day'),
    (outside_day, 'Outside Day'),
    (gap_open_and_reverse, 'Gap Open and Reverse'),
    (vol_clustering, 'Volatility Clustering'),
    (trend_following_after_breakout, 'Trend Following After Breakout'),
    (price_vs_moving_average, 'Price vs Moving Average'),
    (volume_spike, 'Volume Spike'),
    (high_low_volatility_spread, 'High-Low Volatility Spread'),
    (relative_strength_index, 'RSI Signal'),
]

# ====== Run All Signal Functions on Data ======

def run_all_signals(df):
    df_out = df.copy()
    for func, name in SIGNAL_FUNCTIONS:
        df_out = func(df_out)
    return df_out

# ====== Prepare Summary Table ======

def summarize_signals(df):
    records = []
    for asset, group in df.groupby('asset'):
        record = {'asset': asset}
        for _, name in SIGNAL_FUNCTIONS:
            col_name = name.lower().replace(' ', '_') + '_signal'
            if col_name in group.columns:
                record[name] = group[col_name].sum()
            else:
                record[name] = 0
        records.append(record)
    return pd.DataFrame(records)

# ====== Dash App ======

df_raw = generate_artificial_data(N=10, T=120)
df_signals = run_all_signals(df_raw)
summary_df = summarize_signals(df_signals)

app = dash.Dash(__name__)
server = app.server

app.layout = html.Div([
    html.H1("ðŸ“ˆ Multi-Signal Pattern Detection Dashboard"),

    html.Div([
        html.Label("Filter assets by minimum signal count (any signal):"),
        dcc.Slider(
            id='min-signal-slider',
            min=0,
            max=int(summary_df.drop('asset', axis=1).max().max()),
            step=1,
            value=1,
            marks={i: str(i) for i in range(0, int(summary_df.drop('asset', axis=1).max().max())+1)},
        )
    ], style={'width': '50%', 'padding': '20px'}),

    html.H3("Signal Summary Table"),
    dash_table.DataTable(
        id='summary-table',
        columns=[{"name": i, "id": i} for i in summary_df.columns],
        data=summary_df.to_dict('records'),
        page_size=10,
        sort_action='native',
        style_table={'overflowX': 'auto'},
        style_cell={'textAlign': 'center'},
    ),

    html.H3("Select Asset:"),
    dcc.Dropdown(
        id='asset-selector',
        options=[{'label': a, 'value': a} for a in summary_df['asset']],
        value=summary_df['asset'].iloc[0]
    ),

    html.H3("Select Signal to Highlight:"),
    dcc.Dropdown(
        id='signal-selector',
        options=[{'label': name, 'value': name.lower().replace(' ', '_') + '_signal'} for _, name in SIGNAL_FUNCTIONS],
        value='intraday_reversals_signal'
    ),

    dcc.Graph(id='price-chart', style={'height': '700px'}),
])

@app.callback(
    Output('summary-table', 'data'),
    Output('asset-selector', 'options'),
    Input('min-signal-slider', 'value'),
)
def update_summary(min_signal):
    # Filter assets by total sum of signals >= min_signal
    signal_cols = [name.lower().replace(' ', '_') + '_signal' for _, name in SIGNAL_FUNCTIONS]
    summary_df['total_signals'] = summary_df[signal_cols].sum(axis=1)
    filtered = summary_df[summary_df['total_signals'] >= min_signal].copy()
    filtered = filtered.drop(columns=['total_signals'])
    options = [{'label': a, 'value': a} for a in filtered['asset']]
    data = filtered.to_dict('records')
    return data, options

@app.callback(
    Output('price-chart', 'figure'),
    Input('asset-selector', 'value'),
    Input('signal-selector', 'value'),
)
def update_chart(asset, signal_col):
    dfa = df_signals[df_signals['
